---
title: "DDIR: Domain-Disentangled Invariant Representation Learning for Tailored Predictions"
collection: publications
category: manuscripts
permalink: /publication/4-2025-DDIR
excerpt: 'Traditional training struggles with large datasets due to distributional differences. Domain generalization (DG) methods, like DIR learning, perform well with domain shifts but often hurt in-distribution performance. We propose DDIR learning, which preserves domain-orthogonal invariant (DOI) information without redundancy. DDIR extracts domain-invariant and DOI features using a disentanglement loss, reducing complexity. During inference, it optimizes DOI selection for tailored predictions.'
date: 2025-3-17
venue: 'Knowledge-Based Systems'
paperurl: 'https://www.sciencedirect.com/science/article/pii/S0950705125004691'
citation: 'Y. Ma et al., "DDIR: Domain-Disentangled Invariant Representation Learning for Tailored Predictions," in Knowledge-Based Systems 2025.'
---

Traditional training methods often struggle to scale effectively with large datasets due to significant distributional differences. Domain generalization (DG) aims to address the challenge of generalizing across multiple-source domains and improving performance in unknown target domains. While many DG methods, such as domain-invariant representation (DIR) learning, excel in handling significant distribution shifts, they often sacrifice performance on in-distribution (IID) data. This trade-off is crucial in real-world applications with uncertain distribution shifts, spanning both out-of-distribution (OOD) and IID scenarios. 

![image](https://raw.githubusercontent.com/FByyyyuan/FByyyyuan.github.io/master/files/FB004.pdf)

To address this, we identify DIR's limitation in neglecting task-relevant non-domain-invariant information, termed Domain-Orthogonal Invariant (DOI) information. We propose the Domain-Disentangled Invariant Representation (DDIR) learning, which retains DOI information without introducing redundancy. Our method introduces an information disentanglement loss to extract domain-invariant and different DOI information within a single backbone, achieving lower spatial complexity. Moreover, during inference, we propose optimal DOI selection approaches for individual target samples to avoid utilizing redundant DOI information, enabling tailored predictions for each target sample. Experiments demonstrate DDIR's effectiveness in enhancing generalization performance across IID and OOD scenarios.


An overall pipeline of the proposed Domain-Disentangled Invariant Representation learning framework.

![image](https://raw.githubusercontent.com/FByyyyuan/FByyyyuan.github.io/master/files/FB004-2.pdf)

## Resources 
ðŸ”— [GitHub Repository](https://github.com/FByyyyuan/DDIR)  
ðŸ“„ [Paper Link](https://www.sciencedirect.com/science/article/pii/S0950705125004691)  



